#!/usr/bin/env bash
set -euo pipefail

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SERVER="france"                                      # SSH host alias
REMOTE_WEB="/var/www/isthelclcpoolopen.ca/html"      # Web root on server
REMOTE_SCRAPERS="/home/gruberb/scrapers"              # Scrapers dir under your home

BUILD_DIR="build"            # CRAâ€™s default output
APP_TAR="app.tar.gz"
SCRAPERS_TAR="scrapers.tar.gz"

# â”€â”€â”€ CLEANUP ON EXIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cleanup() {
  rm -f "$APP_TAR" "$SCRAPERS_TAR"
}
trap cleanup EXIT

# â”€â”€â”€ 1) BUILD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ”§ Running React buildâ€¦"
npm run build
[ -d "$BUILD_DIR" ] || { echo "âŒ Build failed: '$BUILD_DIR' not found"; exit 1; }

# â”€â”€â”€ 2) PACKAGE TARBALLS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ“¦ Packaging web app â†’ $APP_TAR"
tar -C "$BUILD_DIR" -czf "$APP_TAR" .

echo "ğŸ“¦ Packaging scrapers â†’ $SCRAPERS_TAR"
tar --exclude='node_modules' --exclude='data/*.json' -C scrapers -czf "$SCRAPERS_TAR" .

# â”€â”€â”€ 3) UPLOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸš€ Uploading artifacts to $SERVER..."
scp "$APP_TAR" "$SCRAPERS_TAR" "$SERVER":/tmp/

# â”€â”€â”€ 4) REMOTE DEPLOY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ssh "$SERVER" bash <<EOF
# First, bring your variables into this remote shell:
REMOTE_WEB="$REMOTE_WEB"
REMOTE_SCRAPERS="$REMOTE_SCRAPERS"
APP_TAR="$APP_TAR"
SCRAPERS_TAR="$SCRAPERS_TAR"

set -euo pipefail

echo "ğŸ‘‰ Clearing & extracting web appâ€¦"
rm -rf "\$REMOTE_WEB"/*
mkdir -p "\$REMOTE_WEB"
tar -xzf /tmp/\$APP_TAR -C "\$REMOTE_WEB"
rm /tmp/\$APP_TAR
chmod -R 775 "\$REMOTE_WEB"

echo "ğŸ‘‰ Deploying scrapersâ€¦"
rm -rf "\$REMOTE_SCRAPERS"
mkdir -p "\$REMOTE_SCRAPERS/logs" "\$REMOTE_SCRAPERS/data"
tar -xzf /tmp/\$SCRAPERS_TAR -C "\$REMOTE_SCRAPERS"
rm /tmp/\$SCRAPERS_TAR

cd "\$REMOTE_SCRAPERS"
npm install --production
chmod +x *.js

echo "ğŸ‘‰ Ensuring crontab entriesâ€¦"
declare -a CRONS=(
  "*/30 * * * * cd \$REMOTE_SCRAPERS && node pool-scraper.js >> \$REMOTE_SCRAPERS/logs/pool-scraper.log 2>&1"
  "0 1 * * *  cd \$REMOTE_SCRAPERS && node skating-scraper.js >> \$REMOTE_SCRAPERS/logs/skating-scraper.log 2>&1"
  "0 2 * * *  cd \$REMOTE_SCRAPERS && node libraries-scraper.js >> \$REMOTE_SCRAPERS/logs/libraries-scraper.log 2>&1"
  "*/31 * * * * cp \$REMOTE_SCRAPERS/data/*.json \$REMOTE_WEB/data/"
)

# Rebuild crontab without duplicates
( crontab -l 2>/dev/null \
    | grep -Fv -f <(printf "%s\n" "\${CRONS[@]}") \
  ; printf "%s\n" "\${CRONS[@]}" ) \
  | crontab -

echo "âœ… Deployment complete!"
EOF

echo "ğŸ‰ All done!"
